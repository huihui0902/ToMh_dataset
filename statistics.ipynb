{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens:  512290\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Count tokens.\"\"\"\n",
    "import os\n",
    "import nltk\n",
    "import itertools\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "folder = 'data_ToMh'\n",
    "lengths = [1, 2, 3]\n",
    "orders = [0, 1, 2, 3, 4]\n",
    "prompts = ['CoT', 'MC']\n",
    "tells = ['No_Tell', 'Tell']\n",
    "\n",
    "count_tokens = 0\n",
    "\n",
    "for tell, prompt, length, order, sample_num in itertools.product(tells, prompts, lengths, orders, range(1, 21)):\n",
    "    filename = os.path.join(folder, tell, prompt, f'length_{length}', f'length_{length}_sample_{sample_num}', f'length_{length}_sample_{sample_num}_order_{order}.txt')\n",
    "    # Open and read the txt file:\n",
    "    with open(filename, 'r') as file:\n",
    "        data = file.read()\n",
    "    # Tokenize the data:\n",
    "    tokens = word_tokenize(data)\n",
    "    count_tokens += len(tokens)\n",
    "\n",
    "# Print the number of tokens:\n",
    "print(\"Number of tokens: \", count_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
